{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd598d3",
   "metadata": {},
   "source": [
    "## ‚úÖ **9. Handling Errors Gracefully**\n",
    "\n",
    "* **Unauthorized:** Wrong or missing API key\n",
    "* **Rate Limit Exceeded:** Too many requests too fast\n",
    "* **Quota Exceeded:** You used all your credits\n",
    "\n",
    "Use `try-except` blocks to catch and display errors.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **10. Rate Limits & Quotas**\n",
    "\n",
    "* Each account has limits (e.g., 60 requests/minute).\n",
    "* Paid plans offer higher limits.\n",
    "* Going over these = **errors or blocks**.\n",
    "* Your API key tracks usage.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **11. Best Practices Summary**\n",
    "\n",
    "| Practice          | Why It‚Äôs Important                   |\n",
    "| ----------------- | ------------------------------------ |\n",
    "| ‚úÖ Use `.env` file | Hides secret keys                    |\n",
    "| ‚úÖ Use try-except  | Prevent crashes from errors          |\n",
    "| ‚úÖ Check docs      | Stay updated with latest usage rules |\n",
    "| ‚úÖ Respect limits  | Avoid account suspension             |\n",
    "| ‚úÖ Test keys       | Ensure they work before production   |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **12. Final Thoughts**\n",
    "\n",
    "AI APIs (like OpenAI's) allow developers to build smart apps by connecting to powerful language models.\n",
    "\n",
    "By following:\n",
    "\n",
    "* Key security,\n",
    "* API request structure,\n",
    "* Good error handling,\n",
    "* Documentation guidance...\n",
    "\n",
    "...you can safely and efficiently integrate AI into your apps.\n",
    "\n",
    "---\n",
    "\n",
    "## üîú **Next Lesson Preview**\n",
    "\n",
    "‚û°Ô∏è Learn how to use **Google‚Äôs AI APIs** (like PaLM and Gemini)\n",
    "‚û°Ô∏è Understand how different providers compare\n",
    "‚û°Ô∏è Learn to switch between providers in your projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f56a92d",
   "metadata": {},
   "source": [
    "## ‚úÖ **1. What is an API and an AI API?**\n",
    "\n",
    "**API (Application Programming Interface):**\n",
    "It is a way for two software systems to talk to each other. You (the client) send a request, and the server responds.\n",
    "\n",
    "**AI API:**\n",
    "These are APIs that give you access to artificial intelligence models (like ChatGPT). You can send a **prompt**, and the AI sends back a **response**.\n",
    "\n",
    "**Example:**\n",
    "You send a message: *‚ÄúTranslate this sentence into French‚Äù*, and the AI replies with the translation.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **2. Why Use API Keys?**\n",
    "\n",
    "**API Key = Secret Passcode**\n",
    "\n",
    "* Identifies who is using the API\n",
    "* Prevents abuse (e.g., too many requests, spam)\n",
    "* Limits usage according to your plan (free/paid)\n",
    "\n",
    "**Without it:** Anyone could misuse the system.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **3. How to Get and Use an API Key (OpenAI Example)**\n",
    "\n",
    "### üìå Steps to Generate API Key:\n",
    "\n",
    "1. Log in to [https://platform.openai.com](https://platform.openai.com)\n",
    "2. Go to **\"API Keys\"**\n",
    "3. Click **\"Create Key\"** (name it for clarity, e.g., \"Project1\\_Key\")\n",
    "4. Copy it ‚Äì it won't be shown again!\n",
    "## ‚úÖ **4. How to Secure the API Key**\n",
    "\n",
    "### ‚ùå **DON‚ÄôT:**\n",
    "\n",
    "* Never write the key directly into your Python file (`openai.api_key = \"sk-...\"`)\n",
    "\n",
    "### ‚úÖ **DO:**\n",
    "\n",
    "1. Create a `.env` file in your project folder\n",
    "2. Add this line:\n",
    "\n",
    "   ```\n",
    "   OPENAI_API_KEY=your_actual_key_here\n",
    "   ```\n",
    "3. Use `python-dotenv` to load it into your Python code.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **5. Set Up Your Project (Installation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64381bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c0bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (1.93.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4c331",
   "metadata": {},
   "source": [
    "## ‚úÖ **6. Python Code Setup**\n",
    "### we can load API keys from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f6e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_API_KEY loaded successfully.\n",
      "GOOGLE_API_KEY loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os # Importing os for environment variable handling\n",
    "from dotenv import load_dotenv # Load environment variables from .env file\n",
    "import openai # Importing OpenAI library\n",
    "\n",
    "load_dotenv()  # Load variables from .env file\n",
    "\n",
    "# Function to safely load API key\n",
    "def get_api_key(key_name): # Function to safely load API key\n",
    "    try: # Try to load the key from the environment\n",
    "        key = os.getenv(key_name) # Get the key from the environment\n",
    "        if key: \n",
    "            print(f\"{key_name} loaded successfully.\") # Print success message\n",
    "        else:\n",
    "            print(f\"{key_name} not found.\")\n",
    "        return key\n",
    "    except Exception as e:  # Handle any exceptions that occur\n",
    "        print(f\"Error loading key: {e}\")  # Print error message\n",
    "        return None\n",
    "\n",
    "openai.api_key = get_api_key(\"OPEN_API_KEY\") # Load the API key from the environment\n",
    "openai.api_key = get_api_key(\"GOOGLE_API_KEY\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0e2e3",
   "metadata": {},
   "source": [
    "### ‚úÖ **Purpose of the Code:**\n",
    "\n",
    "This code securely loads your **OpenAI API key** from a `.env` file and sets it up so your Python program can use the OpenAI API (e.g., for ChatGPT queries) **without exposing the key directly in the code.**\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Line-by-Line Explanation:**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `import os`\n",
    "\n",
    "* The `os` module in Python allows you to **interact with the operating system**.\n",
    "* Here, we use it to **read environment variables** (like your API key from the `.env` file).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `from dotenv import load_dotenv`\n",
    "\n",
    "* This imports the `load_dotenv` function from the `python-dotenv` package.\n",
    "* `load_dotenv()` is used to **read key-value pairs from a `.env` file** and load them into the environment variables of your program.\n",
    "\n",
    "> üìå `.env` file contains sensitive information like:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=sk-abc123yourapikey\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `import openai`\n",
    "\n",
    "* This imports the `openai` Python package.\n",
    "* This package provides the functions you need to **connect to OpenAI‚Äôs services** (e.g., GPT models).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `load_dotenv()`\n",
    "\n",
    "* This command **loads the `.env` file** and adds all variables inside it to your system‚Äôs environment.\n",
    "* For example, after this command, you can access the variable `OPENAI_API_KEY` using `os.getenv()`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ The Function: `get_api_key(key_name)`\n",
    "\n",
    "```python\n",
    "def get_api_key(key_name):\n",
    "```\n",
    "\n",
    "This function is defined to **retrieve any API key** by its name from environment variables.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Inside the function:\n",
    "\n",
    "```python\n",
    "    try:\n",
    "        key = os.getenv(key_name)\n",
    "```\n",
    "\n",
    "* `os.getenv(key_name)` tries to fetch the value of the environment variable named `key_name` (e.g., `\"OPENAI_API_KEY\"`).\n",
    "* If found, the key is stored in the variable `key`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `if key:`\n",
    "\n",
    "Checks if the key exists:\n",
    "\n",
    "* ‚úÖ If the key exists:\n",
    "\n",
    "  ```python\n",
    "  print(f\"{key_name} loaded successfully.\")\n",
    "  ```\n",
    "\n",
    "* ‚ùå If the key is not found:\n",
    "\n",
    "  ```python\n",
    "  print(f\"{key_name} not found.\")\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `return key`\n",
    "\n",
    "* The function returns the value of the key (which is a string) so it can be used in other parts of your code.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Error Handling\n",
    "\n",
    "```python\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading key: {e}\")\n",
    "        return None\n",
    "```\n",
    "\n",
    "* If something goes wrong while loading the key (e.g., `.env` file is missing), it will **catch the error** and print an error message instead of crashing the program.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ This Line:\n",
    "\n",
    "```python\n",
    "openai.api_key = get_api_key(\"OPENAI_API_KEY\")\n",
    "```\n",
    "\n",
    "* This **calls the function** `get_api_key()` with `\"OPENAI_API_KEY\"` as an argument.\n",
    "* It gets the actual API key string (e.g., `\"sk-abc123...\"`) from the environment.\n",
    "* Then it **sets that key to `openai.api_key`**, which is required to authenticate your requests to the OpenAI API.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Final Result:**\n",
    "\n",
    "Now, anywhere in your code, you can call OpenAI functions like:\n",
    "\n",
    "```python\n",
    "response = openai.ChatCompletion.create(...)\n",
    "```\n",
    "\n",
    "...and it will use the API key securely loaded from your `.env` file.\n",
    "\n",
    "---\n",
    "\n",
    "### üîê **Why Is This Important?**\n",
    "\n",
    "* **Security:** Avoids hardcoding secret keys in your Python file.\n",
    "* **Portability:** You can share your code without leaking your API key.\n",
    "* **Flexibility:** Easily change keys in the `.env` file without touching your main Python code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14688cfc",
   "metadata": {},
   "source": [
    "## Setup the OpenAI Client\n",
    "Now we will create an OpenAi clint usnig our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4917b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import the open api client\n",
    "from openai import OpenAI # Importing OpenAI client\n",
    "# Create an instance of the OpenAI client\n",
    "client = OpenAI(api_key=openai.api_key) # Create OpenAI client with the API key\n",
    "# if the key is loaded successfully, This will print the success message\n",
    "if client:\n",
    "    print(\"OpenAI client created successfully.\")  # Print success message\n",
    "else:\n",
    "    print(\"Failed to create OpenAI client. Check your API key.\")  # Print error message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750233ea",
   "metadata": {},
   "source": [
    "## ‚úÖ **7. Making a Chat Request (Simple Function)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3590c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain the concept of API in one sentence.\n",
      "Responce: Error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: hsqhdiqwhdd. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "def get_ai_responce(prompt):\n",
    "    \"\"\"\n",
    "    Finction to get AI response from OpenAIs GPT-4.1 model.\n",
    "    Args\n",
    "        prompt (str): The input prompt for the AI model.\n",
    "    Returns\n",
    "        str: The AI's response to the prompt.\n",
    "\n",
    "        \"\"\"\n",
    "    try:\n",
    "        # Create a chat completion request to the OpenAI API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",  # Use latest available\n",
    "            # provide the messages in the chat format\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            # Set parameters for the response\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        ) # Send the request to the OpenAI API\n",
    "        return response.choices[0].message['content'].strip() # Return the AI's response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "prompt = \"Explain the concept of API in one sentence.\"\n",
    "response = get_ai_responce(prompt)  # Get the AI's response to the prompt\n",
    "# Print the AI's response\n",
    "print(f'Prompt: {prompt}')\n",
    "print(f'Responce: {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c340602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f9838ca",
   "metadata": {},
   "source": [
    "## ‚úÖ **8. Key Components of an API Request**\n",
    "\n",
    "| Component     | Description                                          |\n",
    "| ------------- | ---------------------------------------------------- |\n",
    "| `client`      | Your Python code using OpenAI‚Äôs SDK                  |\n",
    "| `prompt`      | Your message to the AI                               |\n",
    "| `model`       | The AI model (like `gpt-4`, `gpt-3.5`)               |\n",
    "| `messages`    | A list of roles: system, user, assistant             |\n",
    "| `temperature` | Controls creativity (0 = factual, 1 = more creative) |\n",
    "| `max_tokens`  | Limits the length of the reply                       |\n",
    "| `response`    | The AI‚Äôs reply                                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caff0c9",
   "metadata": {},
   "source": [
    "# Simple Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3971df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae004788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_API_KEY loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os # Importing os for environment variable handling\n",
    "from dotenv import load_dotenv # Load environment variables from .env file\n",
    "import openai # Importing OpenAI library\n",
    "\n",
    "load_dotenv()  # Load variables from .env file\n",
    "\n",
    "# Function to safely load API key\n",
    "def get_api_key(key_name): # Function to safely load API key\n",
    "    try: # Try to load the key from the environment\n",
    "        key = os.getenv(key_name) # Get the key from the environment\n",
    "        if key: \n",
    "            print(f\"{key_name} loaded successfully.\") # Print success message\n",
    "        else:\n",
    "            print(f\"{key_name} not found.\")\n",
    "        return key\n",
    "    except Exception as e:  # Handle any exceptions that occur\n",
    "        print(f\"Error loading key: {e}\")  # Print error message\n",
    "        return None\n",
    "\n",
    "openai.api_key = get_api_key(\"OPEN_API_KEY\") # Load the API key from the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32840f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responce_from_chatgpt(prompt):\n",
    "  prompt = (f\"Identify and return the sentiment either positive or negative from the given. text: {prompt}\")\n",
    "  responce = openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "          {\"role\": \"system\", \"content\": \"Your are a hepfull sentiment analyzer\"},\n",
    "          {\"role\": \"user\", \"content\":prompt}\n",
    "      ],\n",
    "\n",
    "      temperature = 0.1\n",
    "  )\n",
    "  sentiment = responce[\"choices\"][0][\"message\"][\"content\"]\n",
    "  return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac04445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_taxt = \"I don,t like playing footbol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "769189be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_responce_from_chatgpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_taxt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m, in \u001b[0;36mget_responce_from_chatgpt\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_responce_from_chatgpt\u001b[39m(prompt):\n\u001b[0;32m      2\u001b[0m   prompt \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentify and return the sentiment either positive or negative from the given. text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m   responce \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYour are a hepfull sentiment analyzer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m   sentiment \u001b[38;5;241m=\u001b[39m responce[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m sentiment\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages\\openai\\_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1237\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1246\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1247\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\first_env\\lib\\site-packages\\openai\\_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "get_responce_from_chatgpt(input_taxt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
